{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52400fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjsk1\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f9981",
   "metadata": {},
   "source": [
    "## XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038efb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y= torch.FloatTensor([[0],[1],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87136ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1= torch.nn.Linear(2,2,bias=True)\n",
    "linear2=torch.nn.Linear(2,1,bias=True)\n",
    "sigmoid=torch.nn.Sigmoid()\n",
    "model=torch.nn.Sequential(linear1,sigmoid,linear2,sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba0471e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7663730382919312\n",
      "100 0.6933186054229736\n",
      "200 0.6932241320610046\n",
      "300 0.6931861639022827\n",
      "400 0.693166971206665\n",
      "500 0.6931553483009338\n",
      "600 0.6931467056274414\n",
      "700 0.6931384801864624\n",
      "800 0.6931287050247192\n",
      "900 0.6931148767471313\n",
      "1000 0.6930917501449585\n",
      "1100 0.6930487155914307\n",
      "1200 0.6929554343223572\n",
      "1300 0.6927096843719482\n",
      "1400 0.691815197467804\n",
      "1500 0.6860268712043762\n",
      "1600 0.6282649636268616\n",
      "1700 0.413867712020874\n",
      "1800 0.12728853523731232\n",
      "1900 0.06094200909137726\n",
      "2000 0.03874177485704422\n",
      "2100 0.028097189962863922\n",
      "2200 0.02193659171462059\n",
      "2300 0.017945772036910057\n",
      "2400 0.01516011729836464\n",
      "2500 0.013109810650348663\n",
      "2600 0.011540025472640991\n",
      "2700 0.010300795547664165\n",
      "2800 0.009298373945057392\n",
      "2900 0.008471278473734856\n",
      "3000 0.007777562830597162\n",
      "3100 0.007187572307884693\n",
      "3200 0.006679747719317675\n",
      "3300 0.006238165777176619\n",
      "3400 0.005850786343216896\n",
      "3500 0.005508147180080414\n",
      "3600 0.005203068722039461\n",
      "3700 0.004929674323648214\n",
      "3800 0.004683325532823801\n",
      "3900 0.004460167605429888\n",
      "4000 0.004257162567228079\n",
      "4100 0.004071663599461317\n",
      "4200 0.003901505609974265\n",
      "4300 0.0037449004594236612\n",
      "4400 0.0036002416163682938\n",
      "4500 0.0034662974067032337\n",
      "4600 0.0033418810926377773\n",
      "4700 0.003226003609597683\n",
      "4800 0.0031178684439510107\n",
      "4900 0.0030166367068886757\n",
      "5000 0.0029217672999948263\n",
      "5100 0.0028326462488621473\n",
      "5200 0.002748733852058649\n",
      "5300 0.0026696405839174986\n",
      "5400 0.0025949161499738693\n",
      "5500 0.00252427626401186\n",
      "5600 0.0024572720285505056\n",
      "5700 0.0023937677033245564\n",
      "5800 0.0023334643337875605\n",
      "5900 0.002276062034070492\n",
      "6000 0.002221426460891962\n",
      "6100 0.0021693329326808453\n",
      "6200 0.0021196166053414345\n",
      "6300 0.0020720979664474726\n",
      "6400 0.0020266573410481215\n",
      "6500 0.0019831303507089615\n",
      "6600 0.0019414565758779645\n",
      "6700 0.0019014716381207108\n",
      "6800 0.0018631007988005877\n",
      "6900 0.0018262544181197882\n",
      "7000 0.0017908127047121525\n",
      "7100 0.0017567010363563895\n",
      "7200 0.0017238592263311148\n",
      "7300 0.0016922128852456808\n",
      "7400 0.0016617317451164126\n",
      "7500 0.0016322815790772438\n",
      "7600 0.0016038769390434027\n",
      "7700 0.001576413749717176\n",
      "7800 0.001549936132505536\n",
      "7900 0.0015242802910506725\n",
      "8000 0.0014994607772678137\n",
      "8100 0.001475418102927506\n",
      "8200 0.001452151918783784\n",
      "8300 0.0014296026201918721\n",
      "8400 0.001407740288414061\n",
      "8500 0.0013865202199667692\n",
      "8600 0.0013659570831805468\n",
      "8700 0.0013459466863423586\n",
      "8800 0.001326533267274499\n",
      "8900 0.0013076724717393517\n",
      "9000 0.0012893193634226918\n",
      "9100 0.0012715186458081007\n",
      "9200 0.0012541809119284153\n",
      "9300 0.0012372910277917981\n",
      "9400 0.0012208340922370553\n",
      "9500 0.0012048549251630902\n",
      "9600 0.0011892488691955805\n",
      "9700 0.001174060977064073\n",
      "9800 0.001159246196039021\n",
      "9900 0.0011447896249592304\n",
      "10000 0.0011307065142318606\n"
     ]
    }
   ],
   "source": [
    "criterion=torch.nn.BCELoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1)\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis=model(X)\n",
    "    cost=criterion(hypothesis,Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step %100==0:\n",
    "        print(step,cost.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835218c",
   "metadata": {},
   "source": [
    "## MNIST USING DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "737e8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "mnist_train= dsets.MNIST(root='MNIST_data/',train=True, transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19b755ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test= dsets.MNIST(root='MNIST_data/',train=False, transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3742a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0678e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)\n",
    "criterion=torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer=torch.optim.SGD(linear.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "19c4b4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.534764349\n",
      "Epoch: 0002 cost = 0.359182149\n",
      "Epoch: 0003 cost = 0.331175208\n",
      "Epoch: 0004 cost = 0.316532463\n",
      "Epoch: 0005 cost = 0.307358682\n",
      "Epoch: 0006 cost = 0.300414354\n",
      "Epoch: 0007 cost = 0.295144439\n",
      "Epoch: 0008 cost = 0.290909857\n",
      "Epoch: 0009 cost = 0.287505209\n",
      "Epoch: 0010 cost = 0.284474164\n",
      "Epoch: 0011 cost = 0.281967610\n",
      "Epoch: 0012 cost = 0.279934585\n",
      "Epoch: 0013 cost = 0.277872592\n",
      "Epoch: 0014 cost = 0.276308477\n",
      "Epoch: 0015 cost = 0.274320900\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        \n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "372b8ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8799999952316284\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # not computing gradient    test data이니\n",
    "    X_test=mnist_test.test_data.view(-1,28*28).float().to(device)\n",
    "    Y_test=mnist_test.test_labels.to(device)\n",
    "    prediction=linear(X_test)\n",
    "    correct_prediction=torch.argmax(prediction,1) ==Y_test\n",
    "    accuracy=correct_prediction.float().mean()\n",
    "    print(accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b2fe5e",
   "metadata": {},
   "source": [
    "## weight initialization( xavier, He)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c09695cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_uniform_(tensor,gain=1):\n",
    "    fan_in,fan_out=_calculate_fan_in_and_fan_out(tensor)\n",
    "    std=gain*math.sqrt(2.0/(fan_in+fan_out))\n",
    "    a=math.sqrt(3.0)*std\n",
    "    with torch.no_grad():\n",
    "        return tensor.uniform_(-a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f81bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "608f3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0327425b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "70e50270",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1=torch.nn.Linear(784,256,bias=True)\n",
    "linear2=torch.nn.Linear(256,256,bias=True)\n",
    "linear3=torch.nn.Linear(256,10,bias=True)\n",
    "relu=torch.nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "358ff10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0215, -0.0894,  0.0598,  ...,  0.0200,  0.0203,  0.1212],\n",
       "        [ 0.0078,  0.1378,  0.0920,  ...,  0.0975,  0.1458, -0.0302],\n",
       "        [ 0.1270, -0.1296,  0.1049,  ...,  0.0124,  0.1173, -0.0901],\n",
       "        ...,\n",
       "        [ 0.0661, -0.1025,  0.1437,  ...,  0.0784,  0.0977, -0.0396],\n",
       "        [ 0.0430, -0.1274, -0.0134,  ..., -0.0582,  0.1201,  0.1479],\n",
       "        [-0.1433,  0.0200, -0.0568,  ...,  0.0787,  0.0428, -0.0036]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.xavier_uniform_(linear1.weight) #package\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f0eb749",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69846d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # Softmax is internally computed.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd2c8cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.246783793\n",
      "Epoch: 0002 cost = 0.093234085\n",
      "Epoch: 0003 cost = 0.062067624\n",
      "Epoch: 0004 cost = 0.043566491\n",
      "Epoch: 0005 cost = 0.032832675\n",
      "Epoch: 0006 cost = 0.026513761\n",
      "Epoch: 0007 cost = 0.020483099\n",
      "Epoch: 0008 cost = 0.017960707\n",
      "Epoch: 0009 cost = 0.015639452\n",
      "Epoch: 0010 cost = 0.014098583\n",
      "Epoch: 0011 cost = 0.013838690\n",
      "Epoch: 0012 cost = 0.011658964\n",
      "Epoch: 0013 cost = 0.012876031\n",
      "Epoch: 0014 cost = 0.009459957\n",
      "Epoch: 0015 cost = 0.005646684\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90de5d8",
   "metadata": {},
   "source": [
    "## dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7401951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1=torch.nn.Linear(784,256,bias=True)\n",
    "linear2=torch.nn.Linear(256,256,bias=True)\n",
    "linear3=torch.nn.Linear(256,10,bias=True)\n",
    "relu=torch.nn.ReLU()\n",
    "dropout=torch.nn.Dropout(p=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01199488",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1, relu, dropout,linear2, relu,dropout, linear3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9040a536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 2.305563927\n",
      "Epoch: 0002 cost = 2.305354595\n",
      "Epoch: 0003 cost = 2.305301905\n",
      "Epoch: 0004 cost = 2.305222988\n",
      "Epoch: 0005 cost = 2.305372000\n",
      "Epoch: 0006 cost = 2.305401564\n",
      "Epoch: 0007 cost = 2.305252790\n",
      "Epoch: 0008 cost = 2.305263281\n",
      "Epoch: 0009 cost = 2.305448055\n",
      "Epoch: 0010 cost = 2.305222750\n",
      "Epoch: 0011 cost = 2.305374146\n",
      "Epoch: 0012 cost = 2.305341005\n",
      "Epoch: 0013 cost = 2.305399418\n",
      "Epoch: 0014 cost = 2.305401564\n",
      "Epoch: 0015 cost = 2.305389166\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # reshape input image into [batch_size by 784]\n",
    "        # label is not one-hot encoded\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc119ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
